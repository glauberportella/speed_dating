{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "rating_partner_participant = ['attractive_partner','sincere_partner','intelligence_parter', \n",
    "                             'funny_partner', 'ambition_partner', 'shared_interests_partner']\n",
    "partner_cols = ['pref_o_attractive','pref_o_sincere','pref_o_intelligence','pref_o_funny','pref_o_ambitious','pref_o_shared_interests']\n",
    "participant_cols = ['attractive_important', 'sincere_important', 'intelligence_important', 'funny_important', 'ambition_important', 'shared_interests_important']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dating = pd.read_csv('dating-full.csv')\n",
    "count_quotes = 0\n",
    "count_lowercase = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_quotes(column):\n",
    "    global count_quotes\n",
    "    count = column.str.count(\"\\'.*\\'\").sum()\n",
    "#     print (count)\n",
    "    if count_quotes != count:\n",
    "        count_quotes += count\n",
    "    return column.str.strip('\\'')\n",
    "\n",
    "def convert_lowercase(column):\n",
    "    global count_lowercase\n",
    "    count_lowercase = len(column)- column.str.islower().sum()\n",
    "#     print (count_lowercase)\n",
    "    return column.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dating[['race','race_o','field']] = dating[['race','race_o','field']].apply(remove_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dating[['field']] = dating[['field']].apply(convert_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Quotes removed from', count_quotes, 'cells')\n",
    "print('Standardized', count_lowercase , 'cells to lower case.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_encoder_by_field = {}\n",
    "def get_encoding(column):\n",
    "    column = column.astype('category')\n",
    "    encoding = {}\n",
    "    for i, category in enumerate(column.cat.categories):\n",
    "        encoding[category] = i\n",
    "    global_encoder_by_field[column.name] = encoding\n",
    "    return column.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dating[['race','race_o','gender','field']] = dating[['race','race_o','gender','field']].apply(get_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Value assigned for male in column gender:', global_encoder_by_field['gender']['male'])\n",
    "print ('Value assigned for European/Caucasian-American in column race:', global_encoder_by_field['race']['European/Caucasian-American'])\n",
    "print ('Value assigned for Latino/Hispanic American in column race o:', global_encoder_by_field['race_o']['Latino/Hispanic American'])\n",
    "print ('Value assigned for law in column field:', global_encoder_by_field['field']['law'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_partner = 0\n",
    "total_participant = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,6):\n",
    "    total_partner += dating[partner_cols[i]]\n",
    "    total_participant += dating[participant_cols[i]]\n",
    "# print (total_partner)\n",
    "# print (total_participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,6):\n",
    "    dating[partner_cols[i]]/=total_partner\n",
    "    dating[participant_cols[i]]/=total_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,6):\n",
    "    participant_mean = dating[participant_cols[i]].sum()/len(dating[participant_cols[i]])\n",
    "    print ('Mean of ', participant_cols[i], ':', round(participant_mean, 2))\n",
    "for i in range(0,6): \n",
    "    partner_mean = dating[partner_cols[i]].sum()/len(dating[partner_cols[i]])\n",
    "    print ('Mean of ', partner_cols[i], ':', round(partner_mean, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dating.to_csv('dating.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_print_participant_mean(dataframe):\n",
    "    mean_scores = []\n",
    "    for i in range(0,6):\n",
    "        participant_mean = dataframe[participant_cols[i]].sum()/len(dataframe[participant_cols[i]])\n",
    "        print ('Mean of ', participant_cols[i], ':', round(participant_mean, 2))\n",
    "        mean_scores.append(participant_mean)\n",
    "    return mean_scores\n",
    "\n",
    "dating_female = dating[dating['gender'] == 0]\n",
    "dating_male = dating[dating['gender'] == 1]\n",
    "female_mean_scores = get_print_participant_mean(dating_female)\n",
    "male_mean_scores = get_print_participant_mean(dating_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ind = np.arange(6)\n",
    "width = 0.35\n",
    "p1 = plt.bar(ind, female_mean_scores, width,color = 'pink')\n",
    "p2 = plt.bar(ind+width, male_mean_scores, width, color = 'blue')\n",
    "plt.ylabel('Mean Scores')\n",
    "plt.title('Preference scores of participants by gender')\n",
    "plt.xticks(ind+width/2, (participant_cols[0], participant_cols[1], participant_cols[2], \n",
    "                 participant_cols[3], participant_cols[4], participant_cols[5]), rotation=80)\n",
    "plt.yticks(np.arange(0,0.5,0.05))\n",
    "plt.legend((p1[0], p2[0]), ('Female', 'Male'))\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('gender_barplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distinct_values_rating_partner(dataframe, attribute):\n",
    "    print (dataframe[attribute].nunique()) \n",
    "    return (dataframe[attribute].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_values = []\n",
    "for i in range(0,6):\n",
    "    unique_values.append(get_distinct_values_rating_partner(dating, rating_partner_participant[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_success_rate(dataframe, attribute, value):\n",
    "    dating_attribute_value = dataframe[dataframe[attribute] == value]\n",
    "    dating_success = dating_attribute_value[dating_attribute_value['decision'] == 1]\n",
    "    return len(dating_success)*1.0/len(dating_attribute_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_success_rate(dating, rating_partner_participant[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "success_rates_all_attributes = []\n",
    "for i in range(6):\n",
    "        success_rate_attribute = []\n",
    "        for value in unique_values[i]:\n",
    "            success_rate_attribute.append(get_success_rate(dating, rating_partner_participant[i], value))\n",
    "        success_rates_all_attributes.append(success_rate_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (success_rates_all_attributes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(6):\n",
    "    area = np.pi*3\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(unique_values[i], success_rates_all_attributes[i], s=area)\n",
    "\n",
    "    plt.title('Scatter Plot for Partners who Perform Well on ' + rating_partner_participant[i])\n",
    "    plt.xlabel('Attribute Value for ' + rating_partner_participant[i])\n",
    "    plt.ylabel('Success Rate')\n",
    "\n",
    "    plt.xticks(np.arange(0,11,1))\n",
    "    plt.yticks(np.arange(0,1.1,0.1))\n",
    "    plt.show()\n",
    "    plt.savefig('scatter_plot_' + rating_partner_participant[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dating = pd.read_csv(\"dating.csv\")\n",
    "'''\n",
    "clean data for columns gaming and reading\n",
    "'''\n",
    "column = 'gaming'\n",
    "range_highest = 10\n",
    "dating.loc[dating[column] > range_highest,column] = range_highest\n",
    "dating.loc[dating['reading'] > range_highest,'reading'] = range_highest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binned_column(dataframe, column, num_bins, bin_range):\n",
    "    dataframe[column] = pd.cut(dataframe[column], bin_range, include_lowest = True,\n",
    "                               labels = np.arange(num_bins), retbins = False)\n",
    "    return dataframe[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_binned_cols = ['gender', 'race', 'race_o', 'samerace', 'field', 'decision']\n",
    "age_cols = ['age', 'age_o']\n",
    "num_bins = 5\n",
    "for column in dating:\n",
    "    if column not in non_binned_cols:\n",
    "        bin_range = np.arange(0,11,(10-0)/num_bins)\n",
    "        '''\n",
    "        Change bin range if needed\n",
    "        '''\n",
    "        if column in age_cols:\n",
    "            bin_range = np.arange(18,59,(58-18)/num_bins)\n",
    "#             print (\"bin range for age \", column)\n",
    "        elif column in partner_cols or column in participant_cols:\n",
    "            bin_range = np.arange(0,1.1,(1.0)/num_bins)\n",
    "#             print (\"different bin range \", column)\n",
    "        elif column == 'interests_correlate':\n",
    "            bin_range = np.arange(-1,1.1,(1+1)/num_bins)\n",
    "#             print (\"interest column\", column)\n",
    "        \n",
    "        '''\n",
    "        get binned column\n",
    "        '''\n",
    "        dating[column] = get_binned_column(dating, column, num_bins, bin_range)\n",
    "#         print (column, \": \", dating[column].values_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :  [3710, 2932, 97, 0, 5]\n",
      "age_o :  [3704, 2899, 136, 0, 5]\n",
      "importance_same_race :  [2980, 1213, 977, 1013, 561]\n",
      "importance_same_religion :  [3203, 1188, 1110, 742, 501]\n",
      "pref_o_attractive :  [4333, 1987, 344, 51, 29]\n",
      "pref_o_sincere :  [5500, 1225, 19, 0, 0]\n",
      "pref_o_intelligence :  [4601, 2062, 81, 0, 0]\n",
      "pref_o_funny :  [5616, 1103, 25, 0, 0]\n",
      "pref_o_ambitious :  [6656, 88, 0, 0, 0]\n",
      "pref_o_shared_interests :  [6467, 277, 0, 0, 0]\n",
      "attractive_important :  [4323, 2017, 328, 57, 19]\n",
      "sincere_important :  [5495, 1235, 14, 0, 0]\n",
      "intelligence_important :  [4606, 2071, 67, 0, 0]\n",
      "funny_important :  [5588, 1128, 28, 0, 0]\n",
      "ambition_important :  [6644, 100, 0, 0, 0]\n",
      "shared_interests_important :  [6494, 250, 0, 0, 0]\n",
      "attractive :  [18, 276, 1462, 4122, 866]\n",
      "sincere :  [33, 117, 487, 2715, 3392]\n",
      "intelligence :  [34, 185, 1049, 3190, 2286]\n",
      "funny :  [0, 19, 221, 3191, 3313]\n",
      "ambition :  [84, 327, 1070, 2876, 2387]\n",
      "attractive_partner :  [284, 948, 2418, 2390, 704]\n",
      "sincere_partner :  [94, 353, 1627, 3282, 1388]\n",
      "intelligence_parter :  [36, 193, 1509, 3509, 1497]\n",
      "funny_partner :  [279, 733, 2296, 2600, 836]\n",
      "ambition_partner :  [119, 473, 2258, 2804, 1090]\n",
      "shared_interests_partner :  [701, 1269, 2536, 1774, 464]\n",
      "sports :  [650, 961, 1369, 2077, 1687]\n",
      "tvsports :  [2151, 1292, 1233, 1383, 685]\n",
      "exercise :  [619, 952, 1775, 2115, 1283]\n",
      "dining :  [39, 172, 1118, 2797, 2618]\n",
      "museums :  [117, 732, 1417, 2737, 1741]\n",
      "art :  [224, 946, 1557, 2500, 1517]\n",
      "hiking :  [963, 1386, 1575, 1855, 965]\n",
      "gaming :  [2565, 1522, 1435, 979, 243]\n",
      "clubbing :  [912, 1068, 1668, 2193, 903]\n",
      "reading :  [131, 398, 1071, 2317, 2827]\n",
      "tv :  [1188, 1216, 1999, 1642, 699]\n",
      "theater :  [288, 811, 1585, 2300, 1760]\n",
      "movies :  [45, 248, 843, 2783, 2825]\n",
      "concerts :  [222, 777, 1752, 2282, 1711]\n",
      "music :  [62, 196, 1106, 2583, 2797]\n",
      "shopping :  [1093, 1098, 1709, 1643, 1201]\n",
      "yoga :  [2285, 1392, 1369, 1056, 642]\n",
      "interests_correlate :  [18, 758, 2520, 2875, 573]\n",
      "expected_happy_with_sd_people :  [321, 1262, 3292, 1596, 273]\n",
      "like :  [273, 865, 2539, 2560, 507]\n"
     ]
    }
   ],
   "source": [
    "for column in dating:\n",
    "    if column not in non_binned_cols:\n",
    "        count = dating[column].value_counts(sort=False)\n",
    "        print (column, \": \", count.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dating.to_csv(\"dating-binned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "split dataset\n",
    "'''\n",
    "testset=dating.sample(frac=0.2,random_state=47)\n",
    "trainset=dating.drop(testset.index)\n",
    "testset.to_csv(\"testSet.csv\", index = False)\n",
    "trainset.to_csv(\"trainingSet.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('trainingSet.csv')\n",
    "testset = pd.read_csv('testSet.csv')\n",
    "count_dict_yes = {}\n",
    "count_dict_no = {}\n",
    "for column in trainset:\n",
    "    count_dict_yes[column] = trainset[trainset['decision'] == 1][column].value_counts(sort=False).to_dict()\n",
    "    count_dict_no[column] = trainset[trainset['decision'] == 0][column].value_counts(sort=False).to_dict()\n",
    "    print ('for column', column, 'bin count for decision 1 are', \n",
    "           count_dict_yes[column])\n",
    "    print ('for column', column, 'bin count for decision 0 are',\n",
    "           count_dict_no[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_probability(attribute, value, decision):\n",
    "    if decision == 1:\n",
    "        value_count = 0\n",
    "        if value in count_dict_yes[attribute]:\n",
    "            value_count = count_dict_yes[attribute][value]\n",
    "        return (value_count+1.0)/(count_dict_yes['decision'][1]+len(count_dict_yes[attribute]))\n",
    "    elif decision == 0:\n",
    "        value_count = 0\n",
    "        if value in count_dict_no[attribute]:\n",
    "            value_count = count_dict_no[attribute][value]\n",
    "        return (value_count+1.0)/(count_dict_no['decision'][0]+len(count_dict_no[attribute]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_probability_dec_1 = count_dict_yes['decision'][1]/(count_dict_no['decision'][0]+count_dict_yes['decision'][1])\n",
    "prior_probability_dec_0 = count_dict_no['decision'][0]/(count_dict_no['decision'][0]+count_dict_yes['decision'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_row(row):\n",
    "    correct = 0\n",
    "    prob_dec_1 = 1\n",
    "    prob_dec_0 = 1\n",
    "    for column in count_dict_yes:\n",
    "        if column != 'decision':\n",
    "#                 prob_dec_1 += np.log(get_probability(column, row[column], 1))\n",
    "#                 prob_dec_0 += np.log(get_probability(column, row[column], 0))\n",
    "                '''\n",
    "                dont take logs\n",
    "                '''\n",
    "                prob_dec_1 *= get_probability(column, row[column], 1)\n",
    "                prob_dec_0 *= get_probability(column, row[column], 0)\n",
    "    '''\n",
    "    multiply by prior probabilities\n",
    "    '''\n",
    "#     prob_dec_1 += np.log(prior_probability_dec_1)\n",
    "#     prob_dec_0 += np.log(prior_probability_dec_0)\n",
    "    # dont take logs\n",
    "    prob_dec_1 *= prior_probability_dec_1\n",
    "    prob_dec_0 *= prior_probability_dec_0\n",
    "    \n",
    "    predicted_value = 0\n",
    "    true_value = row['decision']\n",
    "    if prob_dec_1 > prob_dec_0:\n",
    "        predicted_value = 1\n",
    "    if predicted_value == true_value:\n",
    "        correct = 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(dataset):  \n",
    "    dataset['correct_prediction'] = dataset.apply(inference_row, axis=1)\n",
    "    correct_prediction_dict = dataset['correct_prediction'].value_counts().to_dict()\n",
    "    return correct_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = inference(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (correct_predictions[1]/(correct_predictions[1] + correct_predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in count_dict_yes:\n",
    "    print (column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in trainset:\n",
    "    print (column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
